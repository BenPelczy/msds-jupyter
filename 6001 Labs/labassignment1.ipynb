{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 1: How to Get Yourself Unstuck\n",
    "## DS 6001: Practice and Application of Data Science\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way.\n",
    "\n",
    "### Problem 0\n",
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "Python is open-source, and that’s beautiful: it means that Python is maintained by a world-wide community of volunteers, that Python develops at the same rate as advancements in science, and that Python is completely free of charge. But one downside of being open-source is that different people design many alternative ways to perform the same task in Python.\n",
    "\n",
    "Read the following Stack Overflow post: https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas/46912050. The question is simply how to rename the columns of a dataframe using Pandas. Count how many unique different solutions were proposed, and write this number in your lab report. (Hint: the number of solutions is not the number of answers to the posted question.)\n",
    "\n",
    "Remember: your goal as a data scientist needs to be to process/clean/wrangle/manage data as quickly as possible while still doing it correctly. A big part of that job is knowing how to seek help to find the right answer quickly. Given the number of proposed solutions on this Stack Overflow page, what’s the problem with developing a habit of using Google and Stack Overflow as your first source for seeking help? (2 points)\n",
    "\n",
    "**The number of unique different solutions in the Stack Overflow post is roughly 40. This high number of potential solutions means that looking at Stack Overflow or Google first makes it difficult to find the best solution - or even a correct one - without first sifting through all of the answers.**\n",
    "\n",
    "### Problem 2\n",
    "There are several functions implemented in Python to calculate a logarithm. Both the `numpy` and `math` libraries have a `log()` function. Your task in this problem is to calculate log$_3(7)$ directly (without using the change-of-base formula). Note that this particular log has a base of 3, which is unusual. For this problem:\n",
    "\n",
    "* Write code to display the docstrings for each function.\n",
    "\n",
    "* Read the docstrings and explain, in words in your lab report, whether it is possible to use each function to calculate log$_3(7)$ or not. Why did you come to this conclusion?\n",
    "\n",
    "**According to the docstrings shown below, np.log() can only calculate the natural (base *e*) log and so cannot calculate log$_3(7)$, while math.log() has base as parameter and therefore can calculate log$_3(7)$.**\n",
    "\n",
    "If possible, use one or both functions to calculate log$_3(7)$ and display the output. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mCall signature:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m            ufunc\n",
       "\u001b[0;31mString form:\u001b[0m     <ufunc 'log'>\n",
       "\u001b[0;31mFile:\u001b[0m            /opt/miniconda3/lib/python3.12/site-packages/numpy/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m      \n",
       "log(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature])\n",
       "\n",
       "Natural logarithm, element-wise.\n",
       "\n",
       "The natural logarithm `log` is the inverse of the exponential function,\n",
       "so that `log(exp(x)) = x`. The natural logarithm is logarithm in base\n",
       "`e`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x : array_like\n",
       "    Input value.\n",
       "out : ndarray, None, or tuple of ndarray and None, optional\n",
       "    A location into which the result is stored. If provided, it must have\n",
       "    a shape that the inputs broadcast to. If not provided or None,\n",
       "    a freshly-allocated array is returned. A tuple (possible only as a\n",
       "    keyword argument) must have length equal to the number of outputs.\n",
       "where : array_like, optional\n",
       "    This condition is broadcast over the input. At locations where the\n",
       "    condition is True, the `out` array will be set to the ufunc result.\n",
       "    Elsewhere, the `out` array will retain its original value.\n",
       "    Note that if an uninitialized `out` array is created via the default\n",
       "    ``out=None``, locations within it where the condition is False will\n",
       "    remain uninitialized.\n",
       "**kwargs\n",
       "    For other keyword-only arguments, see the\n",
       "    :ref:`ufunc docs <ufuncs.kwargs>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "y : ndarray\n",
       "    The natural logarithm of `x`, element-wise.\n",
       "    This is a scalar if `x` is a scalar.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "log10, log2, log1p, emath.log\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Logarithm is a multivalued function: for each `x` there is an infinite\n",
       "number of `z` such that `exp(z) = x`. The convention is to return the\n",
       "`z` whose imaginary part lies in `(-pi, pi]`.\n",
       "\n",
       "For real-valued input data types, `log` always returns real output. For\n",
       "each value that cannot be expressed as a real number or infinity, it\n",
       "yields ``nan`` and sets the `invalid` floating point error flag.\n",
       "\n",
       "For complex-valued input, `log` is a complex analytical function that\n",
       "has a branch cut `[-inf, 0]` and is continuous from above on it. `log`\n",
       "handles the floating-point negative zero as an infinitesimal negative\n",
       "number, conforming to the C99 standard.\n",
       "\n",
       "In the cases where the input has a negative real part and a very small\n",
       "negative complex part (approaching 0), the result is so close to `-pi`\n",
       "that it evaluates to exactly `-pi`.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] M. Abramowitz and I.A. Stegun, \"Handbook of Mathematical Functions\",\n",
       "       10th printing, 1964, pp. 67.\n",
       "       https://personal.math.ubc.ca/~cbm/aands/page_67.htm\n",
       ".. [2] Wikipedia, \"Logarithm\". https://en.wikipedia.org/wiki/Logarithm\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> np.log([1, np.e, np.e**2, 0])\n",
       "array([  0.,   1.,   2., -inf])\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "Functions that operate element by element on whole arrays.\n",
       "\n",
       "To see the documentation for a specific ufunc, use `info`.  For\n",
       "example, ``np.info(np.sin)``.  Because ufuncs are written in C\n",
       "(for speed) and linked into Python with NumPy's ufunc facility,\n",
       "Python's help() function finds this page whenever help() is called\n",
       "on a ufunc.\n",
       "\n",
       "A detailed explanation of ufuncs can be found in the docs for :ref:`ufuncs`.\n",
       "\n",
       "**Calling ufuncs:** ``op(*x[, out], where=True, **kwargs)``\n",
       "\n",
       "Apply `op` to the arguments `*x` elementwise, broadcasting the arguments.\n",
       "\n",
       "The broadcasting rules are:\n",
       "\n",
       "* Dimensions of length 1 may be prepended to either array.\n",
       "* Arrays may be repeated along dimensions of length 1.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*x : array_like\n",
       "    Input arrays.\n",
       "out : ndarray, None, or tuple of ndarray and None, optional\n",
       "    Alternate array object(s) in which to put the result; if provided, it\n",
       "    must have a shape that the inputs broadcast to. A tuple of arrays\n",
       "    (possible only as a keyword argument) must have length equal to the\n",
       "    number of outputs; use None for uninitialized outputs to be\n",
       "    allocated by the ufunc.\n",
       "where : array_like, optional\n",
       "    This condition is broadcast over the input. At locations where the\n",
       "    condition is True, the `out` array will be set to the ufunc result.\n",
       "    Elsewhere, the `out` array will retain its original value.\n",
       "    Note that if an uninitialized `out` array is created via the default\n",
       "    ``out=None``, locations within it where the condition is False will\n",
       "    remain uninitialized.\n",
       "**kwargs\n",
       "    For other keyword-only arguments, see the :ref:`ufunc docs <ufuncs.kwargs>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "r : ndarray or tuple of ndarray\n",
       "    `r` will have the shape that the arrays in `x` broadcast to; if `out` is\n",
       "    provided, it will be returned. If not, `r` will be allocated and\n",
       "    may contain uninitialized values. If the function has more than one\n",
       "    output, then the result will be a tuple of arrays."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "log(x, [base=math.e])\n",
       "Return the logarithm of x to the given base.\n",
       "\n",
       "If the base is not specified, returns the natural logarithm (base e) of x.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?math.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7712437491614221\n"
     ]
    }
   ],
   "source": [
    "print(math.log(7, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Open a console window and place it next to your notebook in Jupyter labs. Load the kernel from the notebook into the console, then call up the docstring for the `pd.DataFrame` function. Take a screenshot and include it in your lab report. (To include a locally saved image named `screenshot.jpg`, for example, create a Markdown cell and paste \n",
    "```\n",
    "<img src=\"screenshot.jpg\" width=600>\n",
    "```\n",
    "(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshot.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: for some reason, the pdf version of this notebook does not load this image, despite me copying the example text exactly (and it showing up fine in the notebook itself). However, I have fixed this by appending the image to the end of the file manually.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "Search through the questions on Stack Overflow tagged as Python questions: https://stackoverflow.com/questions/tagged/python. Find a question in which an answerer exhibits passive toxic behavior as defined in this module's notebook. Provide a link, and describe what specific behavior leads you to identify this answer as toxic. (2 points)\n",
    "\n",
    "**In the question https://stackoverflow.com/questions/23186128/python-why-is-this-wrong, the answerer is unnecessarily sarcastic and passive aggressive in their response, especially the first paragraph. Their comments shame the question asker to the point where they feel they must apologize \"for not being clear\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "Search through the questions on Stack Overflow tagged as Python questions: https://stackoverflow.com/questions/tagged/python. Find a question in which a questioner self-sabotages by asking the question in a way that the community does not appreciate. Provide a link, and describe what the questioner did specifically to annoy the community of answerers. (2 points)\n",
    "\n",
    "**In the question https://stackoverflow.com/questions/52119760/what-is-wrong-with-my-code-which-deals-with-creating-python-dictionaries, in addition to asking a very basic question (which Stack Overflow users do not like answering), the questioner uses non-ASCII quotes in their code, which seems to confuse and frustrate the responders.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "These days there are so many Marvel superheros, but only six superheros count as original Avengers: Hulk, Captain America, Iron Man, Black Widow, Hawkeye, and Thor. I wrote a function, `is_avenger()`, that takes a string as an input. The function looks to see if this string is the name of one of the original six Avengers. If so, it prints that the string is an original Avenger, and if not, it prints that the string is not an original Avenger. Here’s the code for the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_avenger(name):\n",
    "    if name==\"Hulk\" or name==\"Captain America\" or name==\"Iron Man\" or name==\"Black Widow\" or name==\"Hawkeye\" or name==\"Thor\":\n",
    "        print(name  + \"'s an original Avenger!\")\n",
    "    else:\n",
    "        print(name + \" is NOT an original Avenger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether this function is working, I pass the names of some original Avengers to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Widow's an original Avenger!\n"
     ]
    }
   ],
   "source": [
    "is_avenger(\"Black Widow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iron Man's an original Avenger!\n"
     ]
    }
   ],
   "source": [
    "is_avenger(\"Iron Man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hulk's an original Avenger!\n"
     ]
    }
   ],
   "source": [
    "is_avenger(\"Hulk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! But next, I pass some other strings to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider-Man is NOT an original Avenger.\n"
     ]
    }
   ],
   "source": [
    "is_avenger(\"Spider-Man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyonce is NOT an original Avenger.\n"
     ]
    }
   ],
   "source": [
    "is_avenger(\"Beyonce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyonce is a hero, but she was too busy going on tour to be in the Avengers movie. Also, Spiderman definitely was NOT an original Avenger. It turns out that this function will display that any string we write here is an original Avenger, which is incorrect. To fix this function, let’s turn to Stack Overflow.\n",
    "\n",
    "#### Part a\n",
    "The first step to solving a problem using Stack Overflow is to do a comprehensive search of available resources to try to solve the problem. There is a post on Stack Overflow that very specifically solves our problem. Do a Google search and find this post. In your lab report, write the link to this Stack Overflow page, and the search terms you entered into Google to find this page.\n",
    "\n",
    "Then apply the solution on this Stack Overflow page to fix the `is_avenger()` function, and test the function to confirm that it works as we expect. (2 points)\n",
    "\n",
    "**Despite making numerous attempts at finding the referenced post with both general and specific search terms, including 'avengers only returns true site:stackoverflow.com', 'superhero names if statement error python site:stackoverflow.com', and '\"is_avenger\" python site:stackoverflow.com', and even searching in Stack Overflow directly, I was unable to actually find it. I have nevertheless applied a solution to the above function.**\n",
    "\n",
    "#### Part b\n",
    "Suppose that no Stack Overflow posts yet existed to help us solve this problem. It would be time to consider writing a post ourselves. In your lab report, write a good title for this post. Do NOT copy the title to the posts you found for part a. (Hint: for details on how to write a good title see the slides or https://stackoverflow.com/help/how-to-ask) (2 points)\n",
    "\n",
    "**Why is my Python function's if statement only returning true?**\n",
    "\n",
    "#### Part c\n",
    "One characteristic of a Stack Overflow post that is likely to get good responses is a minimal working example. A minimal working example is code with the following properties:\n",
    "\n",
    "1. It can be executed on anyone’s local machine without needing a data file or a hard-to-get package or module\n",
    "\n",
    "2. It always produces the problematic output\n",
    "\n",
    "3. It using as few lines of code as possible, and is written in the simplest way to write that code\n",
    "\n",
    "Write a minimal working example for this problem. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is here\n"
     ]
    }
   ],
   "source": [
    "def is_name(name):\n",
    "    if name==\"A\" or \"B\":\n",
    "        print(name  + \" is here\")\n",
    "    else:\n",
    "        print(name + \" is not here\")\n",
    "\n",
    "is_name(\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "This problem will test your ability to use a chatbot based on a large-language model, such as ChatGPT, to do data wrangling. Please sign-up for a [free account to use ChatGPT](https://chat.openai.com/) if you have not already done so, and log on to the chat interface website for ChatGPT.\n",
    "\n",
    "#### Part a\n",
    "The following data comes from a Kaggle project on [Jobs and Salaries in Data Science](https://www.kaggle.com/code/lucasgalanti/jobs-in-data), compiled by Lucas Galanti (though I don't see an attribution to the original data source, so please take these numbers with a grain of salt). Load the data by running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>work_setting</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Data DevOps Engineer</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>EUR</td>\n",
       "      <td>88000</td>\n",
       "      <td>95012</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>Germany</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Data Architect</td>\n",
       "      <td>Data Architecture and Modeling</td>\n",
       "      <td>USD</td>\n",
       "      <td>186000</td>\n",
       "      <td>186000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>In-person</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Data Architect</td>\n",
       "      <td>Data Architecture and Modeling</td>\n",
       "      <td>USD</td>\n",
       "      <td>81800</td>\n",
       "      <td>81800</td>\n",
       "      <td>United States</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>In-person</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Science and Research</td>\n",
       "      <td>USD</td>\n",
       "      <td>212000</td>\n",
       "      <td>212000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>In-person</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Science and Research</td>\n",
       "      <td>USD</td>\n",
       "      <td>93300</td>\n",
       "      <td>93300</td>\n",
       "      <td>United States</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>In-person</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9350</th>\n",
       "      <td>2021</td>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>Data Management and Strategy</td>\n",
       "      <td>USD</td>\n",
       "      <td>165000</td>\n",
       "      <td>165000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9351</th>\n",
       "      <td>2020</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Science and Research</td>\n",
       "      <td>USD</td>\n",
       "      <td>412000</td>\n",
       "      <td>412000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>2021</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Data Science and Research</td>\n",
       "      <td>USD</td>\n",
       "      <td>151000</td>\n",
       "      <td>151000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>2020</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Science and Research</td>\n",
       "      <td>USD</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>2020</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>USD</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9355 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      work_year                 job_title                    job_category  \\\n",
       "0          2023      Data DevOps Engineer                Data Engineering   \n",
       "1          2023            Data Architect  Data Architecture and Modeling   \n",
       "2          2023            Data Architect  Data Architecture and Modeling   \n",
       "3          2023            Data Scientist       Data Science and Research   \n",
       "4          2023            Data Scientist       Data Science and Research   \n",
       "...         ...                       ...                             ...   \n",
       "9350       2021           Data Specialist    Data Management and Strategy   \n",
       "9351       2020            Data Scientist       Data Science and Research   \n",
       "9352       2021  Principal Data Scientist       Data Science and Research   \n",
       "9353       2020            Data Scientist       Data Science and Research   \n",
       "9354       2020     Business Data Analyst                   Data Analysis   \n",
       "\n",
       "     salary_currency  salary  salary_in_usd employee_residence  \\\n",
       "0                EUR   88000          95012            Germany   \n",
       "1                USD  186000         186000      United States   \n",
       "2                USD   81800          81800      United States   \n",
       "3                USD  212000         212000      United States   \n",
       "4                USD   93300          93300      United States   \n",
       "...              ...     ...            ...                ...   \n",
       "9350             USD  165000         165000      United States   \n",
       "9351             USD  412000         412000      United States   \n",
       "9352             USD  151000         151000      United States   \n",
       "9353             USD  105000         105000      United States   \n",
       "9354             USD  100000         100000      United States   \n",
       "\n",
       "     experience_level employment_type work_setting company_location  \\\n",
       "0           Mid-level       Full-time       Hybrid          Germany   \n",
       "1              Senior       Full-time    In-person    United States   \n",
       "2              Senior       Full-time    In-person    United States   \n",
       "3              Senior       Full-time    In-person    United States   \n",
       "4              Senior       Full-time    In-person    United States   \n",
       "...               ...             ...          ...              ...   \n",
       "9350           Senior       Full-time       Remote    United States   \n",
       "9351           Senior       Full-time       Remote    United States   \n",
       "9352        Mid-level       Full-time       Remote    United States   \n",
       "9353      Entry-level       Full-time       Remote    United States   \n",
       "9354      Entry-level        Contract       Remote    United States   \n",
       "\n",
       "     company_size  \n",
       "0               L  \n",
       "1               M  \n",
       "2               M  \n",
       "3               M  \n",
       "4               M  \n",
       "...           ...  \n",
       "9350            L  \n",
       "9351            L  \n",
       "9352            L  \n",
       "9353            S  \n",
       "9354            L  \n",
       "\n",
       "[9355 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv('jobs_in_data.csv')\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to manipulate the `jobs` dataframe to create a table with four rows: one for each of the job titles Data Analyst, Data Engineer, Data Scientist, and Machine Learning Engineer; and two columns: one for the year 2022 and one for 2023. Inside each cell should be the average salary (`salary_in_usd`) for that job title and year, rounded to the nearest dollar. The resulting table should look something like this:\n",
    "\n",
    "|                           | 2022   | 2023   |\n",
    "|---------------------------|--------|--------|\n",
    "| Data Analyst              | 108658 | 110988 |\n",
    "| Data Engineer             | 139803 | 149945 |\n",
    "| Data Scientist            | 138529 | 163714 |\n",
    "| Machine Learning Engineer | 151775 | 191026 |\n",
    "\n",
    "Your task is to use ChatGPT -- and ONLY chatGPT -- to generate Python code that uses `pandas` that can generate a dataframe that looks like the above table. For this problem, use markdown cells in your notebook to display both your prompts and ChatGPT's responses. You will almost certainly need to issue several follow-up prompts to get to an answer, and you should list all of your prompts and the responses in your answer.\n",
    "\n",
    "A few points to keep in mind:\n",
    "* You will receive better responses by following the guidelines listed here: https://jkropko.github.io/surfing-the-data-pipeline/ch1.html#method-5-using-a-large-language-model-a-chatbot-to-generate-and-debug-code\n",
    "* You are more likely to get an answer that works by chunking the task into discrete steps. Some of the steps that are needed here are:\n",
    "  * Keep only the rows from 2022 and 2023\n",
    "  * Keep only the rows with job titles Data Analyst, Data Engineer, Data Scientist, and Machine Learning Engineer\n",
    "  * Collapse the data by taking the average `salary_in_usd` within each remaining year and job title combination\n",
    "  * Reshape the data by moving the years to the columns\n",
    "  * Round the average salaries to the nearest dollar\n",
    "\n",
    "Whether you state these specific steps in your prompts or not, and the order in which you state them if you do, is up to you.\n",
    "\n",
    "One last note: remember you are trying to generate code to generate the average salary table, not the table itself. If the code that ChatGPT generates yields using a small sample of the data calculates incorrect averages, that's OK as long as the code works properly for the full dataframe. (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt: Using the pandas library, load in the data found in the csv file on https://www.kaggle.com/code/lucasgalanti/jobs-in-data/input.**\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "To load the data from the CSV file found on Kaggle into a pandas DataFrame, you can use the following steps:\n",
    "\n",
    " 1. Download the dataset: Visit the dataset page on Kaggle and download the CSV file. For example, you can find relevant datasets here, here, or here.\n",
    "\n",
    " 2. Load the CSV file using pandas: Use the read_csv function from pandas to load the CSV file into a DataFrame.\n",
    "\n",
    "Here's a sample code to achieve this:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'path_to_your_downloaded_file.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data.head())\n",
    "```\n",
    "\n",
    "Make sure to replace 'path_to_your_downloaded_file.csv' with the actual path to the downloaded CSV file on your machine. This code snippet will read the CSV file and print the first few rows of the dataset, allowing you to inspect the data structure.\n",
    "\n",
    "**Prompt: Perform a transform function on this dataframe that keeps only the rows with Data Analyst, Data Engineer, Data Scientist, and Machine Learning Engineer from the job_title column, and from those keeps only the rows with 2022 and 2023 from the work_year column.**\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "To perform the required transformations on the DataFrame, you need to filter the rows based on the job_title and work_year columns. Here's how you can do it using pandas:\n",
    "\n",
    " 1. Filter by job titles: Keep only the rows where the job_title is one of \"Data Analyst\", \"Data Engineer\", \"Data Scientist\", or \"Machine Learning Engineer\".\n",
    " 2. Filter by work years: Keep only the rows where the work_year is 2022 or 2023.\n",
    "\n",
    "Here's a sample code to achieve this:\n",
    "\n",
    "```\n",
    "{\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'path_to_your_downloaded_file.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows based on job_title and work_year\n",
    "filtered_data = data[\n",
    "    (data['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (data['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "print(filtered_data.head())\n",
    "}\n",
    "```\n",
    "\n",
    "Make sure to replace 'path_to_your_downloaded_file.csv' with the actual path to your downloaded CSV file. This code snippet will filter the DataFrame and display the first few rows of the filtered data.\n",
    "\n",
    "**Prompt: Using this filtered data, create a table with 2022 and 2023 as columns, the job_title variables as rows, and the cells containing the average salary_in_usd for each year and job title combination.**\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "To create a table with 2022 and 2023 as columns, the job titles as rows, and the cells containing the average salary_in_usd for each year and job title combination, you can use the pandas library to group and pivot the filtered DataFrame. Here's how you can do it:\n",
    "\n",
    " 1. Group the filtered data by job_title and work_year, and then calculate the average salary_in_usd.\n",
    " 2. Pivot the table to have work_year as columns and job_title as rows.\n",
    "\n",
    "Here's the code to achieve this:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'path_to_your_downloaded_file.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows based on job_title and work_year\n",
    "filtered_data = data[\n",
    "    (data['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (data['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Group by job_title and work_year, then calculate the average salary_in_usd\n",
    "grouped_data = filtered_data.groupby(['job_title', 'work_year'])['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have work_year as columns and job_title as rows\n",
    "pivot_table = grouped_data.pivot(index='job_title', columns='work_year', values='salary_in_usd')\n",
    "\n",
    "# Display the resulting pivot table\n",
    "print(pivot_table)\n",
    "```\n",
    "\n",
    "This code snippet will produce a table where the rows are the job titles and the columns are the years 2022 and 2023. The cells in the table will contain the average salary_in_usd for each job title and year combination.\n",
    "\n",
    "Here's a sample output of what the pivot table might look like:\n",
    "\n",
    "```\n",
    "work_year                   2022          2023\n",
    "job_title                                     \n",
    "Data Analyst          70000.0      72000.0\n",
    "Data Engineer         90000.0      95000.0\n",
    "Data Scientist       110000.0     115000.0\n",
    "Machine Learning Engineer 120000.0    125000.0\n",
    "```\n",
    "\n",
    "This table shows the average salaries for each job title in 2022 and 2023.\n",
    "\n",
    "**Prompt: Now create this table with \"work_year\" and \"job_title\" removed, the years as column headers, and the cells rounded to the nearest dollar.**\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "Here's the updated code to create a table with \"work_year\" and \"job_title\" removed, the years as column headers, and the cells rounded to the nearest dollar:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'path_to_your_downloaded_file.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows based on job_title and work_year\n",
    "filtered_data = data[\n",
    "    (data['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (data['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Group by job_title and work_year, then calculate the average salary_in_usd\n",
    "grouped_data = filtered_data.groupby(['job_title', 'work_year'])['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have work_year as columns and job_title as rows\n",
    "pivot_table = grouped_data.pivot(index='job_title', columns='work_year', values='salary_in_usd')\n",
    "\n",
    "# Round the values to the nearest dollar\n",
    "pivot_table = pivot_table.round()\n",
    "\n",
    "# Reset the index to remove \"work_year\" and \"job_title\" from the table\n",
    "pivot_table.reset_index(inplace=True)\n",
    "\n",
    "# Display the resulting pivot table\n",
    "print(pivot_table)\n",
    "```\n",
    "\n",
    "This code will produce a table where the rows are indexed by job titles, and the columns are the years 2022 and 2023, with the salary values rounded to the nearest dollar. Here's an example of what the resulting table might look like:\n",
    "\n",
    "```\n",
    "work_year              job_title     2022     2023\n",
    "0                Data Analyst   70000   72000\n",
    "1                Data Engineer  90000   95000\n",
    "2               Data Scientist 110000 115000\n",
    "3  Machine Learning Engineer 120000 125000\n",
    "```\n",
    "\n",
    "This table shows the average salaries for each job title in 2022 and 2023, rounded to the nearest dollar.\n",
    "\n",
    "**Prompt: Now create this table with \"work_year\" and \"job_title\" removed, and the job titles as row headers.**\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "To create the desired table with \"work_year\" and \"job_title\" removed, and the job titles as row headers, you can use the following updated code:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'path_to_your_downloaded_file.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows based on job_title and work_year\n",
    "filtered_data = data[\n",
    "    (data['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (data['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Group by job_title and work_year, then calculate the average salary_in_usd\n",
    "grouped_data = filtered_data.groupby(['job_title', 'work_year'])['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have work_year as columns and job_title as rows\n",
    "pivot_table = grouped_data.pivot(index='job_title', columns='work_year', values='salary_in_usd')\n",
    "\n",
    "# Round the values to the nearest dollar\n",
    "pivot_table = pivot_table.round()\n",
    "\n",
    "# Display the resulting pivot table\n",
    "print(pivot_table)\n",
    "```\n",
    "\n",
    "This will produce a DataFrame where the job titles are row headers and the columns are the years 2022 and 2023, with salary values rounded to the nearest dollar. The resulting table will look like this:\n",
    "\n",
    "```\n",
    "work_year                   2022      2023\n",
    "job_title                                 \n",
    "Data Analyst            70000.0  72000.0\n",
    "Data Engineer           90000.0  95000.0\n",
    "Data Scientist         110000.0 115000.0\n",
    "Machine Learning Engineer 120000.0 125000.0\n",
    "```\n",
    "\n",
    "To format the table with job titles as row headers and without displaying \"work_year\" and \"job_title\" as headers, you can directly print the DataFrame:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'path_to_your_downloaded_file.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows based on job_title and work_year\n",
    "filtered_data = data[\n",
    "    (data['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (data['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Group by job_title and work_year, then calculate the average salary_in_usd\n",
    "grouped_data = filtered_data.groupby(['job_title', 'work_year'])['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have work_year as columns and job_title as rows\n",
    "pivot_table = grouped_data.pivot(index='job_title', columns='work_year', values='salary_in_usd')\n",
    "\n",
    "# Round the values to the nearest dollar\n",
    "pivot_table = pivot_table.round()\n",
    "\n",
    "# Print the resulting pivot table\n",
    "print(pivot_table)\n",
    "```\n",
    "\n",
    "This will produce the desired table without the \"work_year\" and \"job_title\" as headers and the job titles as row headers.\n",
    "\n",
    "**Prompt: Remove the decimal point from the cell values, also the labels \"work_year\" and \"job_title\" should not be present in the final table.**\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "To produce a final table where the decimal points are removed from the cell values and the labels \"work_year\" and \"job_title\" are not present, you can use the following code:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'path_to_your_downloaded_file.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows based on job_title and work_year\n",
    "filtered_data = data[\n",
    "    (data['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (data['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Group by job_title and work_year, then calculate the average salary_in_usd\n",
    "grouped_data = filtered_data.groupby(['job_title', 'work_year'])['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have work_year as columns and job_title as rows\n",
    "pivot_table = grouped_data.pivot(index='job_title', columns='work_year', values='salary_in_usd')\n",
    "\n",
    "# Round the values to the nearest dollar and convert to integers\n",
    "pivot_table = pivot_table.round().astype(int)\n",
    "\n",
    "# Print the resulting pivot table without the default pandas index name\n",
    "pivot_table.columns.name = None\n",
    "pivot_table.index.name = None\n",
    "print(pivot_table)\n",
    "```\n",
    "\n",
    "This code does the following:\n",
    "\n",
    " 1. Loads the CSV data into a pandas DataFrame.\n",
    " 2. Filters the DataFrame for the specified job titles and work years.\n",
    " 3. Groups the data by job_title and work_year, then calculates the average salary_in_usd.\n",
    " 4. Pivots the table so that work_year becomes the columns and job_title becomes the rows.\n",
    " 5. Rounds the values to the nearest dollar and converts them to integers to remove the decimal points.\n",
    " 6. Removes the column and index names for a cleaner table output.\n",
    "\n",
    "Here is an example of what the resulting table might look like:\n",
    "\n",
    "```\n",
    "                           2022    2023\n",
    "Data Analyst             70000   72000\n",
    "Data Engineer            90000   95000\n",
    "Data Scientist          110000  115000\n",
    "Machine Learning Engineer 120000 125000\n",
    "```\n",
    "\n",
    "This table has job titles as row headers and the years 2022 and 2023 as column headers, with the average salary values rounded to the nearest dollar and displayed as integers.\n",
    "\n",
    "**Prompt: Now print this code with the file_path variable being 'jobs_in_data.csv' and the data variable being renamed to \"jobs\".**\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "Here is the code with the file_path variable set to 'jobs_in_data.csv' and the DataFrame variable renamed to jobs:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the CSV file is named 'jobs_in_data.csv' and located in the current directory\n",
    "file_path = 'jobs_in_data.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "jobs = pd.read_csv(file_path)\n",
    "\n",
    "# Filter rows based on job_title and work_year\n",
    "filtered_jobs = jobs[\n",
    "    (jobs['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (jobs['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Group by job_title and work_year, then calculate the average salary_in_usd\n",
    "grouped_jobs = filtered_jobs.groupby(['job_title', 'work_year'])['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have work_year as columns and job_title as rows\n",
    "pivot_table = grouped_jobs.pivot(index='job_title', columns='work_year', values='salary_in_usd')\n",
    "\n",
    "# Round the values to the nearest dollar and convert to integers\n",
    "pivot_table = pivot_table.round().astype(int)\n",
    "\n",
    "# Print the resulting pivot table without the default pandas index name\n",
    "pivot_table.columns.name = None\n",
    "pivot_table.index.name = None\n",
    "print(pivot_table)\n",
    "```\n",
    "\n",
    "This code will read the data from the jobs_in_data.csv file, filter and process it to create a pivot table with job titles as row headers and years as column headers, and then print the table with the salary values rounded to the nearest dollar and displayed as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             2022    2023\n",
      "Data Analyst               108658  110988\n",
      "Data Engineer              139803  149945\n",
      "Data Scientist             138529  163714\n",
      "Machine Learning Engineer  151775  191026\n"
     ]
    }
   ],
   "source": [
    "# Filter rows based on job_title and work_year\n",
    "filtered_jobs = jobs[\n",
    "    (jobs['job_title'].isin(['Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer'])) &\n",
    "    (jobs['work_year'].isin([2022, 2023]))\n",
    "]\n",
    "\n",
    "# Group by job_title and work_year, then calculate the average salary_in_usd\n",
    "grouped_jobs = filtered_jobs.groupby(['job_title', 'work_year'])['salary_in_usd'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have work_year as columns and job_title as rows\n",
    "pivot_table = grouped_jobs.pivot(index='job_title', columns='work_year', values='salary_in_usd')\n",
    "\n",
    "# Round the values to the nearest dollar and convert to integers\n",
    "pivot_table = pivot_table.round().astype(int)\n",
    "\n",
    "# Print the resulting pivot table without the default pandas index name\n",
    "pivot_table.columns.name = None\n",
    "pivot_table.index.name = None\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Having worked through using ChatGPT for data wrangling, take a moment to reflect on when it makes sense and when it doesn't make sense to use ChatGPT for working with data prior to an analysis. Write a short paragraph here summarizing your thoughts. (1 point)\n",
    "\n",
    "**I am decently impressed by ChatGPT's ability to write clear and effective chunks of data transformation code. However, there were some details in my process that leave me apprehensive. For starters, the cell values in the example table seem to be completely made up, which suggests that ChatGPT did not test the actual dataset. As such, it's probably best to use ChatGPT only with datasets that are verified to be clean, or that you have cleaned yourself. Additionally, ChatGPT struggled most with my request to remove the \"work_year\" and \"job_title\", only successfully doing so once I had instructed it in the clearest possible terms. Therefore, ChatGPT is best used with a specific goal in mind, so that you know exactly how to express what you want it to do.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
